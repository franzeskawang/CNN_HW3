{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import io, transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取圖片\n",
    "def read_img(root='/training/', weight=128,height=128):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    print('Start read the image ...')#\n",
    "    \n",
    "    for i in range(10):#\n",
    "        class_path = root + \"Sample{:0>3d}/\".format(i+1)\n",
    "        print(class_path)#\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = class_path + img_name\n",
    "            img = io.imread(img_path)\n",
    "            img = transform.resize(img, (weight, height,1))\n",
    "            label=[0]*10\n",
    "            label[i]=1\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "            \n",
    "    print('Finished ...')#\n",
    "    imgss=np.asarray(imgs, np.float32)\n",
    "    labelss=np.asarray(labels, np.float32)\n",
    "\n",
    "    return imgss, labelss\n",
    "\n",
    "# 打亂順序\n",
    "def messUpOrder(data, label):\n",
    "    num_example = data.shape[0]#總共幾筆資料\n",
    "    print(\"data.shape:[0]\",data.shape[0])#\n",
    "    new_arange = np.arange(num_example)\n",
    "    np.random.shuffle(new_arange)\n",
    "    data = data[new_arange]\n",
    "    label = label[new_arange]\n",
    "\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_relu(_x):#拿來取代activation=tf.nn.relu\n",
    "    alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                             initializer=tf.constant_initializer(0.0),\n",
    "                             dtype=tf.float32)\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alphas * (_x - abs(_x)) * 0.5\n",
    "    return pos + neg\n",
    "# 構建網絡\n",
    "def buildCNN(weight=128, height=128, color=1, mode=False):\n",
    "    print(\"CNN Structure\")\n",
    "    # 佔位符\n",
    "    x = tf.placeholder(tf.float32, shape=[None, weight, height, color], name='x')#訓練資料\n",
    "    y_ = tf.placeholder(tf.int32, shape=[None, 10], name='y_')#10:label#對的label\n",
    "\n",
    "    # 第一個卷積層 + 池化層\n",
    "    # Input Tensor Shape: [batch_size, 128, 128, 1]\n",
    "    # Output Tensor Shape: [batch_size, 128, 128, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=x,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=parametric_relu,\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    print(\"conv1.shape\",conv1.shape)\n",
    "    # Input Tensor Shape: [batch_size, 128, 128, 32]\n",
    "    # Output Tensor Shape: [batch_size, 64, 64, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    print(\"pool1.shape\",pool1.shape)\n",
    "    \n",
    "    # 第二個卷積層 + 池化層\n",
    "    # Input Tensor Shape: [batch_size, 64, 64, 32]\n",
    "    # Output Tensor Shape: [batch_size, 64, 64, 32]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    print(\"conv2.shape\",conv2.shape)\n",
    "    # Input Tensor Shape: [batch_size, 64, 64, 32]\n",
    "    # Output Tensor Shape: [batch_size, 32, 32, 32]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    print(\"pool2.shape\",pool2.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    # 全連接層\n",
    "    flat = tf.reshape(pool2, [-1, 32*32*32])\n",
    "    dense1 = tf.layers.dense(inputs=flat,\n",
    "                             units=1024,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))\n",
    "    print(\"dense1.shape\",dense1.shape)\n",
    "\n",
    "    \n",
    "    # dropout\n",
    "    dropout = tf.layers.dropout(inputs=dense1, rate=0.4, training=mode)\n",
    "    print(\"dropout.shape\",dropout.shape)\n",
    "    # logits訓練出來的各種機率\n",
    "    logits = tf.layers.dense(inputs=dropout,\n",
    "                             units=10,  \n",
    "                             activation=None,\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))\n",
    "\n",
    "\n",
    "    #loss\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_))   \n",
    "    \n",
    "    #OP\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(loss)\n",
    "    \n",
    "    #loss2=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_))\n",
    "    #train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "    print(\"logits.shape\",logits.shape)\n",
    "    print(\"y_.shape\",y_.shape)\n",
    "    \n",
    "    return logits, x, y_, loss, train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一個函數，按批次取數據\n",
    "def generate_batch(inputs, targets, batch_size):\n",
    "    \n",
    "    sup=len(inputs)\n",
    "    assert batch_size < sup, 'batch_size太大了'\n",
    "    \n",
    "    inputs_data=[]\n",
    "    targets_data = []\n",
    "    r = np.random.choice(range(sup), batch_size, replace=False)\n",
    "    for i in r:\n",
    "        inputs_data.append(inputs[i])  \n",
    "        targets_data.append(targets[i])  \n",
    "    return inputs_data, targets_data\n",
    "\n",
    "# generate_batch test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(root='./training/'):\n",
    "    data, label = read_img(root=root, weight=128,height=128)\n",
    "    x_train, y_train = messUpOrder(data=data, label=label)\n",
    "    test_data, test_label = read_img(root='./validation/', weight=128,height=128)\n",
    "    x_test, y_test = messUpOrder(data=data, label=label)\n",
    " \n",
    "    logits, x, y_, loss, train_op = buildCNN(mode=True)\n",
    "    pred=tf.argmax(logits,axis=1)\n",
    "    gt=tf.argmax(y_,axis=1)\n",
    "    #correct_prediction = tf.equal(pred, gt)\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "    n_epoch = 81\n",
    "    batch_size = 50\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        # Initializing all variables\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            batch_inputs, batch_labels = generate_batch(inputs=x_train, targets=y_train, batch_size=batch_size)\n",
    "            #training\n",
    "            a,b,c,d,e,f,g = sess.run([logits,x, y_,loss,pred,gt,train_op], feed_dict={x: batch_inputs, y_: batch_labels})\n",
    "            #test\n",
    "            a_,b_,c_,d_,e_,f_ = sess.run([logits,x, y_,loss,pred,gt], feed_dict={x: test_data, y_: test_label})\n",
    "            if epoch%10==0:\n",
    "                                \n",
    "                print(\"epoch\",epoch)\n",
    "                print(\"train_loss\",d)\n",
    "                print(\"test_loss\",d_)\n",
    "                correct = np.count_nonzero(np.array(e) == np.array(f))\n",
    "                accuracy = float(correct) / len(f) * 100  \n",
    "                correct_ = np.count_nonzero(np.array(e_) == np.array(f_))\n",
    "                accuracy_ = float(correct_) / len(f_) * 100\n",
    "                print(\"train_acc\",accuracy,\"%\")\n",
    "                print(\"test_acc\",accuracy_,\"%\")\n",
    "                \n",
    "                                        \n",
    "        save_path = saver.save(sess, \"./model/model.ckpt\")\n",
    "        print(\"save_path\",save_path)\n",
    "    sess.close()\n",
    "        # Final embeddings are ready for you to use. \n",
    "        # Need to normalize for practical use\n",
    "\n",
    "\n",
    "\n",
    "def test(root='./validation/'):    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    data, label = read_img(root=root, weight=128,height=128)\n",
    "    x_test, y_test = messUpOrder(data=data, label=label)\n",
    "   \n",
    "    logits, x, y_, loss, train_op = buildCNN(mode=False)\n",
    "    pred=tf.argmax(logits,axis=1)\n",
    "    gt=tf.argmax(y_,axis=1)\n",
    "   \n",
    "    \n",
    "\n",
    "    n_epoch = 1\n",
    "    batch_size = 200\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        # Initializing all variables\n",
    "        tf.initialize_all_variables().run()\n",
    "        saver.restore(sess, \"./model/model.ckpt\")\n",
    "        for epoch in range(n_epoch):\n",
    "            print(\"epoch\",epoch)\n",
    "            batch_inputs, batch_labels = generate_batch(inputs=x_test, targets=y_test, batch_size=batch_size)\n",
    "            p,g = sess.run([pred,gt], feed_dict={x: batch_inputs, y_: batch_labels})\n",
    "            correct_ = np.count_nonzero(np.array(p) == np.array(g))\n",
    "            accuracy_ = float(correct_) / len(p) * 100\n",
    "            print(\"test_acc\",accuracy_,\"%\")\n",
    "\n",
    "    sess.close()\n",
    "    # make your model give prediction for images from data_dir\n",
    "    # the following code is just a placeholder\n",
    "    return p, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read the image ...\n",
      "./training/Sample001/\n",
      "./training/Sample002/\n",
      "./training/Sample003/\n",
      "./training/Sample004/\n",
      "./training/Sample005/\n",
      "./training/Sample006/\n",
      "./training/Sample007/\n",
      "./training/Sample008/\n",
      "./training/Sample009/\n",
      "./training/Sample010/\n",
      "Finished ...\n",
      "data.shape:[0] 650\n",
      "Start read the image ...\n",
      "./validation/Sample001/\n",
      "./validation/Sample002/\n",
      "./validation/Sample003/\n",
      "./validation/Sample004/\n",
      "./validation/Sample005/\n",
      "./validation/Sample006/\n",
      "./validation/Sample007/\n",
      "./validation/Sample008/\n",
      "./validation/Sample009/\n",
      "./validation/Sample010/\n",
      "Finished ...\n",
      "data.shape:[0] 650\n",
      "CNN Structure\n",
      "conv1.shape (?, 128, 128, 32)\n",
      "pool1.shape (?, 64, 64, 32)\n",
      "conv2.shape (?, 64, 64, 32)\n",
      "pool2.shape (?, 32, 32, 32)\n",
      "dense1.shape (?, 1024)\n",
      "dropout.shape (?, 1024)\n",
      "logits.shape (?, 10)\n",
      "y_.shape (?, 10)\n",
      "epoch 0\n",
      "train_loss 2.3027017\n",
      "test_loss 2.3016858\n",
      "train_acc 4.0 %\n",
      "test_acc 9.6 %\n",
      "epoch 10\n",
      "train_loss 2.2886913\n",
      "test_loss 2.2708826\n",
      "train_acc 10.0 %\n",
      "test_acc 10.8 %\n",
      "epoch 20\n",
      "train_loss 1.8557545\n",
      "test_loss 1.8274171\n",
      "train_acc 62.0 %\n",
      "test_acc 49.4 %\n",
      "epoch 30\n",
      "train_loss 0.68099046\n",
      "test_loss 0.70234144\n",
      "train_acc 76.0 %\n",
      "test_acc 78.2 %\n",
      "epoch 40\n",
      "train_loss 0.34121415\n",
      "test_loss 0.31839618\n",
      "train_acc 88.0 %\n",
      "test_acc 91.4 %\n",
      "epoch 50\n",
      "train_loss 0.18790606\n",
      "test_loss 0.28257495\n",
      "train_acc 94.0 %\n",
      "test_acc 90.0 %\n",
      "epoch 60\n",
      "train_loss 0.170512\n",
      "test_loss 0.26421887\n",
      "train_acc 96.0 %\n",
      "test_acc 91.8 %\n",
      "epoch 70\n",
      "train_loss 0.012471314\n",
      "test_loss 0.15997188\n",
      "train_acc 100.0 %\n",
      "test_acc 95.8 %\n",
      "epoch 80\n",
      "train_loss 0.0115846\n",
      "test_loss 0.16852392\n",
      "train_acc 100.0 %\n",
      "test_acc 95.6 %\n",
      "save_path ./model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read the image ...\n",
      "./training/Sample001/\n",
      "./training/Sample002/\n",
      "./training/Sample003/\n",
      "./training/Sample004/\n",
      "./training/Sample005/\n",
      "./training/Sample006/\n",
      "./training/Sample007/\n",
      "./training/Sample008/\n",
      "./training/Sample009/\n",
      "./training/Sample010/\n",
      "Finished ...\n",
      "data.shape:[0] 650\n",
      "CNN Structure\n",
      "conv1.shape (?, 128, 128, 32)\n",
      "pool1.shape (?, 64, 64, 32)\n",
      "conv2.shape (?, 64, 64, 32)\n",
      "pool2.shape (?, 32, 32, 32)\n",
      "dense1.shape (?, 1024)\n",
      "dropout.shape (?, 1024)\n",
      "logits.shape (?, 10)\n",
      "y_.shape (?, 10)\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "epoch 0\n",
      "test_acc 12.0 %\n"
     ]
    }
   ],
   "source": [
    "pred, gt = test(root='./training/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred) == len(gt), \"The length of prediction and ground truth should be the same\"\n",
    "correct = np.count_nonzero(np.array(pred) == np.array(gt))\n",
    "print(\"Accuracy: {}%\".format(float(correct) / len(pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#痕跡器官\n",
    "    # 第三個卷積層 + 池化層 \n",
    "    # Input Tensor Shape: [batch_size, 32, 32, 64]\n",
    "    # Output Tensor Shape: [batch_size, 32, 32, 64]\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    print(\"conv3.shape\",conv3.shape)\n",
    "    # Input Tensor Shape: [batch_size, 32, 32, 64]\n",
    "    # Output Tensor Shape: [batch_size, 16, 16, 64]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    print(\"pool3.shape\",pool3.shape)\n",
    "\n",
    "    # 第四個卷積層 + 池化層 \n",
    "    # Input Tensor Shape: [batch_size, 16, 16, 64]\n",
    "    # Output Tensor Shape: [batch_size, 16, 16, 64]\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    print(\"conv4.shape\",conv4.shape)\n",
    "    # Input Tensor Shape: [batch_size, 16, 16, 64]\n",
    "    # Output Tensor Shape: [batch_size, 8, 8, 64]\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "    print(\"pool4.shape\",pool4.shape)\n",
    "    \n",
    "    \n",
    "    dense2 = tf.layers.dense(inputs=dense1,\n",
    "                             units=512,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))\n",
    "    print(\"dense2.shape\",dense2.shape)\n",
    "    dense3 = tf.layers.dense(inputs=dense1,\n",
    "                             units=256,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))\n",
    "    print(\"dense3.shape\",dense3.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
